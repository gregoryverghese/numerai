{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "american-inventory",
   "metadata": {},
   "source": [
    "Round 255 - prediction results for ensemble model of catboost and lgbmboost. Nothing fancy as of yet. We build on round 254 lgbm by using ensemble model with lgbm + cat. Need to setup proper pipeline for downloading data and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "developing-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numerapi\n",
    "from getpass import getpass\n",
    "import seaborn as sns\n",
    "#from dotenv import load_dotenv, find_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import mse\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import utilities\n",
    "import evaluation\n",
    "from autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detected-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your Numerai Public Key. You can find your key here: https://numer.ai/submit -> ········\n",
      "Please enter your Numerai Secret Key. You can find your key here: https://numer.ai/submit -> ········\n",
      "Please enter your Numerai Model ID. You can find your key here: https://numer.ai/submit -> ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"NUMERAI_PUBLIC_KEY\"] = getpass(\"Please enter your Numerai Public Key. You can find your key here: https://numer.ai/submit -> \")\n",
    "os.environ[\"NUMERAI_SECRET_KEY\"] = getpass(\"Please enter your Numerai Secret Key. You can find your key here: https://numer.ai/submit -> \")\n",
    "os.environ[\"NUMERAI_MODEL_ID\"] = getpass(\"Please enter your Numerai Model ID. You can find your key here: https://numer.ai/submit -> \")\n",
    "\n",
    "public_key = os.environ.get(\"NUMERAI_PUBLIC_KEY\")\n",
    "secret_key = os.environ.get(\"NUMERAI_SECRET_KEY\")\n",
    "model_id = os.environ.get(\"NUMERAI_MODEL_ID\")\n",
    "napi = numerapi.NumerAPI(verbosity=\"info\", public_id=public_key, secret_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dated-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./numerai_dataset_254.zip: 100%|█████████▉| 394M/394M [15:45<00:00, 580kB/s]     2021-03-08 13:30:34,435 INFO numerapi.base_api: unzipping file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./numerai_dataset_254.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "napi.download_current_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cheap-smith",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:17, 38.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Generated! Saving to file ...\n"
     ]
    }
   ],
   "source": [
    "tourn_file = Path(f'./numerai_dataset_{napi.get_current_round()}/numerai_tournament_data.csv')\n",
    "train_file = Path(f'./numerai_dataset_{napi.get_current_round()}/numerai_training_data.csv')\n",
    "processed_train_file = Path('./training_processed.csv')\n",
    "\n",
    "if processed_train_file.exists():\n",
    "    print(\"Loading the processed training data from file\\n\")\n",
    "    training_data = pd.read_csv(processed_train_file)\n",
    "else:\n",
    "    tourn_iter_csv = pd.read_csv(tourn_file, iterator=True, chunksize=1e6)\n",
    "    val_df = pd.concat([chunk[chunk['data_type'] == 'validation'] for chunk in tqdm(tourn_iter_csv)])\n",
    "    tourn_iter_csv.close()\n",
    "    training_data = pd.read_csv(train_file)\n",
    "    training_data = pd.concat([training_data, val_df])\n",
    "    training_data.reset_index(drop=True, inplace=True)\n",
    "    print(\"Training Dataset Generated! Saving to file ...\")\n",
    "    training_data.to_csv(processed_train_file, index=False)\n",
    "\n",
    "\n",
    "feature_cols = training_data.columns[training_data.columns.str.startswith('feature')]\n",
    "target_cols = ['target']\n",
    "\n",
    "train_idx = training_data.index[training_data.data_type=='train'].tolist()\n",
    "val_idx = training_data.index[training_data.data_type=='validation'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "military-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model=load_model('autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "featured-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "  if 'dense' in layer.get_config()['name']:\n",
    "    if layer.get_config()['units']==50:\n",
    "      output=layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "coated-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "encoder=Model(inputs=model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "civil-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_model=pickle.load(open('cat_model_round_254.pkl', 'rb'))\n",
    "lgb_model=pickle.load(open('lgbm_model_round_254.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "attached-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "preds = []\n",
    "\n",
    "chunksize = 5000\n",
    "\n",
    "tourn_iter_csv = pd.read_csv(tourn_file, iterator=True, chunksize=1e6)\n",
    "for chunk in tourn_iter_csv:\n",
    "    live_data = chunk[feature_cols].to_numpy()\n",
    "    x_live_ae = encoder.predict(live_data)\n",
    "    out = lgb_model.predict(x_live_ae)\n",
    "    ids.extend(chunk[\"id\"])\n",
    "    preds.extend(out)\n",
    "tourn_iter_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "successful-colony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0003aa52cab36c2</td>\n",
       "      <td>0.483834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000920ed083903f</td>\n",
       "      <td>0.492721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n0038e640522c4a6</td>\n",
       "      <td>0.519278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n004ac94a87dc54b</td>\n",
       "      <td>0.497608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n0052fe97ea0c05f</td>\n",
       "      <td>0.494105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  n0003aa52cab36c2    0.483834\n",
       "1  n000920ed083903f    0.492721\n",
       "2  n0038e640522c4a6    0.519278\n",
       "3  n004ac94a87dc54b    0.497608\n",
       "4  n0052fe97ea0c05f    0.494105"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'id':ids,\n",
    "    'prediction':preds\n",
    "})\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "protected-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(\"lgb_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-connection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
